{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad8d03e-1228-4594-bb1a-b32843a5e28a",
   "metadata": {},
   "source": [
    "# Prepreocess EWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7327eed-b0d7-4fff-9a03-75cb55cf1c43",
   "metadata": {},
   "source": [
    "## Read files and combined them into one dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9c956c-c7d2-438f-bf00-7d2a374b4ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Region</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Economic Judgment</th>\n",
       "      <th>Sector/Occupation</th>\n",
       "      <th>Reason for Judgment</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>北海道</td>\n",
       "      <td>家計動向関連</td>\n",
       "      <td>◎</td>\n",
       "      <td>－</td>\n",
       "      <td>－</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>北海道</td>\n",
       "      <td>家計動向関連</td>\n",
       "      <td>○</td>\n",
       "      <td>商店街代表者等</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・価格が低下したことにより購買意欲が上向いており、売上点数が増加している。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>北海道</td>\n",
       "      <td>家計動向関連</td>\n",
       "      <td>○</td>\n",
       "      <td>レストラン（高級）スタッフ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・２～３か月前と比べると、売上が伸びている。12月に比べると、２倍の伸びを示している。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>北海道</td>\n",
       "      <td>家計動向関連</td>\n",
       "      <td>□</td>\n",
       "      <td>百貨店の売場主任・担当者</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・３か月前と同様に、客は必要な物でも慎重な購買を行っている。今月スタートの冬物値下げで商品価...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>北海道</td>\n",
       "      <td>家計動向関連</td>\n",
       "      <td>□</td>\n",
       "      <td>スーパーの店長・店員</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・今月は雪が多いせいもあり、良いとはいえない。客単価も悪く、店の状態をみる限り、景気は良いと...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340739</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>沖縄</td>\n",
       "      <td>雇用関連</td>\n",
       "      <td>□</td>\n",
       "      <td>人材派遣会社（総務担当）</td>\n",
       "      <td>求職者数の動き</td>\n",
       "      <td>・求職の新規登録者が増加せず、相変わらず人手不足が続いている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340740</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>沖縄</td>\n",
       "      <td>雇用関連</td>\n",
       "      <td>□</td>\n",
       "      <td>求人情報誌製作会社（営業）</td>\n",
       "      <td>求人数の動き</td>\n",
       "      <td>・全体の求人数は、前月比で５％程度の微減である。３か月前と比較すると増減がなく横ばいである。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340741</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>沖縄</td>\n",
       "      <td>雇用関連</td>\n",
       "      <td>□</td>\n",
       "      <td>学校［大学］（就職支援担当）</td>\n",
       "      <td>それ以外</td>\n",
       "      <td>・物価高が続く限り、消費者は消費意欲を抑えるとみている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340742</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>沖縄</td>\n",
       "      <td>雇用関連</td>\n",
       "      <td>▲</td>\n",
       "      <td>－</td>\n",
       "      <td>－</td>\n",
       "      <td>－</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340743</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>沖縄</td>\n",
       "      <td>雇用関連</td>\n",
       "      <td>×</td>\n",
       "      <td>－</td>\n",
       "      <td>－</td>\n",
       "      <td>－</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340744 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year Month Region   Topic Economic Judgment Sector/Occupation  \\\n",
       "0       2000    01    北海道  家計動向関連                 ◎                 －   \n",
       "1       2000    01    北海道  家計動向関連                 ○           商店街代表者等   \n",
       "2       2000    01    北海道  家計動向関連                 ○     レストラン（高級）スタッフ   \n",
       "3       2000    01    北海道  家計動向関連                 □      百貨店の売場主任・担当者   \n",
       "4       2000    01    北海道  家計動向関連                 □        スーパーの店長・店員   \n",
       "...      ...   ...    ...     ...               ...               ...   \n",
       "340739  2025    02     沖縄    雇用関連                 □      人材派遣会社（総務担当）   \n",
       "340740  2025    02     沖縄    雇用関連                 □     求人情報誌製作会社（営業）   \n",
       "340741  2025    02     沖縄    雇用関連                 □    学校［大学］（就職支援担当）   \n",
       "340742  2025    02     沖縄    雇用関連                 ▲                 －   \n",
       "340743  2025    02     沖縄    雇用関連                 ×                 －   \n",
       "\n",
       "       Reason for Judgment                                            Details  \n",
       "0                        －                                                NaN  \n",
       "1                      NaN              ・価格が低下したことにより購買意欲が上向いており、売上点数が増加している。  \n",
       "2                      NaN        ・２～３か月前と比べると、売上が伸びている。12月に比べると、２倍の伸びを示している。  \n",
       "3                      NaN  ・３か月前と同様に、客は必要な物でも慎重な購買を行っている。今月スタートの冬物値下げで商品価...  \n",
       "4                      NaN  ・今月は雪が多いせいもあり、良いとはいえない。客単価も悪く、店の状態をみる限り、景気は良いと...  \n",
       "...                    ...                                                ...  \n",
       "340739             求職者数の動き                    ・求職の新規登録者が増加せず、相変わらず人手不足が続いている。  \n",
       "340740              求人数の動き  ・全体の求人数は、前月比で５％程度の微減である。３か月前と比較すると増減がなく横ばいである。...  \n",
       "340741                それ以外                       ・物価高が続く限り、消費者は消費意欲を抑えるとみている。  \n",
       "340742                   －                                                  －  \n",
       "340743                   －                                                  －  \n",
       "\n",
       "[340744 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the target folder and filename pattern\n",
    "folder_path = '../data/1_EWS_ja'\n",
    "file_pattern = '*_watcher4.csv'\n",
    "\n",
    "# Get a list of matching CSV file paths\n",
    "csv_files = glob.glob(os.path.join(folder_path, file_pattern))\n",
    "\n",
    "# Function to extract necessary data from each file\n",
    "def extract_EWS_data(df, filename):\n",
    "    # Create empty lists to store extracted data\n",
    "    years = []\n",
    "    months = []\n",
    "    regions = []\n",
    "    topics = []\n",
    "    economic_judgments = []\n",
    "    sectors_or_occupations = []\n",
    "    reasons = []\n",
    "    details = []\n",
    "\n",
    "    # Extract year and month from filename\n",
    "    year = filename[:4]   # First 4 characters\n",
    "    month = filename[4:6] # 5th and 6th characters\n",
    "    \n",
    "    # Keys to extract data\n",
    "    region_keys = ['北海道', '東北', '北関東', '南関東', '甲信越', '東海', '北陸', '近畿', '中国', '四国', '九州', '沖縄']\n",
    "    topic_keys = ['家計', '企業', '雇用']\n",
    "    judge_keys = ['◎', '○', '□', '▲', '×']\n",
    "    \n",
    "    # Variable to keep track of the current region and topic\n",
    "    current_region = None\n",
    "    current_topic = None\n",
    "    \n",
    "    # Iterate over rows to extract data\n",
    "    for index, row in df.iterrows():\n",
    "        row_values = row.tolist()  # Convert row to list\n",
    "\n",
    "        # Skip if all elements are NaN\n",
    "        if pd.Series(row_values).isna().all():\n",
    "            continue\n",
    "\n",
    "        # Update region and topic\n",
    "        if isinstance(row_values[0], str):  # Ensure first column is a string\n",
    "            # Update Region\n",
    "            matched_regions = [region_key for region_key in region_keys if region_key in row_values[0]]\n",
    "            if matched_regions:\n",
    "                current_region = matched_regions[0]\n",
    "            \n",
    "            # Update Topic\n",
    "            matched_topics = [topic_key for topic_key in topic_keys if topic_key in row_values[0]]\n",
    "            if matched_topics:\n",
    "                current_topic = matched_topics[0]\n",
    "                # Replace topic representation\n",
    "                topic_mapping = {'家計': '家計動向関連', '企業': '企業動向関連', '雇用': '雇用関連'}\n",
    "                current_topic = topic_mapping.get(current_topic, current_topic)\n",
    "\n",
    "        # Extract data if the judgment column has valid data\n",
    "        if isinstance(row_values[2], str) and any(judge_key in row_values[2] for judge_key in judge_keys):\n",
    "            years.append(year)\n",
    "            months.append(month)\n",
    "            regions.append(current_region)\n",
    "            topics.append(current_topic)\n",
    "            economic_judgments.append(row_values[2].strip())\n",
    "            sectors_or_occupations.append(row_values[3].strip() if isinstance(row_values[3], str) else np.nan)\n",
    "            reasons.append(row_values[4].strip() if isinstance(row_values[4], str) else np.nan)\n",
    "            details.append(row_values[5].strip() if isinstance(row_values[5], str) else np.nan)\n",
    "    \n",
    "    # Create cleaned dataframe\n",
    "    df_extracted = pd.DataFrame({\n",
    "        'Year': years,\n",
    "        'Month': months,\n",
    "        'Region': regions,\n",
    "        'Topic': topics,\n",
    "        'Economic Judgment': economic_judgments,\n",
    "        'Sector/Occupation': sectors_or_occupations,\n",
    "        'Reason for Judgment': reasons,\n",
    "        'Details': details\n",
    "    })\n",
    "\n",
    "    return df_extracted\n",
    "\n",
    "# Read all matching CSV files into a list of DataFrames\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, encoding='utf-8')  # Try UTF-8 first\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='cp932')  # Try CP932 (Shift_JIS)\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file, encoding='shift_jis')  # Try Shift_JIS as a last resort\n",
    "\n",
    "    # Extract necessary data and append to list\n",
    "    df_extracted = extract_EWS_data(df, os.path.basename(file))\n",
    "    dfs.append(df_extracted)\n",
    "\n",
    "# Merge all DataFrames into one\n",
    "if dfs:\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    display(combined_df)\n",
    "else:\n",
    "    print('No matching CSV files found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f641a5-f8fd-447d-8d9c-42a2af41e477",
   "metadata": {},
   "source": [
    "## Translate Japanese into English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ea3bd-56f1-43c2-9760-0b97b48b3ae9",
   "metadata": {},
   "source": [
    "- By custom dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae769b21-e720-4f02-9761-8e9f28f92770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Region</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Economic Judgment</th>\n",
       "      <th>Sector/Occupation</th>\n",
       "      <th>Reason for Judgment</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>Household Activity</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>No response available</td>\n",
       "      <td>No response available</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>Household Activity</td>\n",
       "      <td>Good</td>\n",
       "      <td>商店街代表者等</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・価格が低下したことにより購買意欲が上向いており、売上点数が増加している。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>Household Activity</td>\n",
       "      <td>Good</td>\n",
       "      <td>レストラン（高級）スタッフ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・２～３か月前と比べると、売上が伸びている。12月に比べると、２倍の伸びを示している。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>Household Activity</td>\n",
       "      <td>Unchanged</td>\n",
       "      <td>百貨店の売場主任・担当者</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・３か月前と同様に、客は必要な物でも慎重な購買を行っている。今月スタートの冬物値下げで商品価...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>01</td>\n",
       "      <td>Hokkaido</td>\n",
       "      <td>Household Activity</td>\n",
       "      <td>Unchanged</td>\n",
       "      <td>スーパーの店長・店員</td>\n",
       "      <td>NaN</td>\n",
       "      <td>・今月は雪が多いせいもあり、良いとはいえない。客単価も悪く、店の状態をみる限り、景気は良いと...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340739</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>Okinawa</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Unchanged</td>\n",
       "      <td>人材派遣会社（総務担当）</td>\n",
       "      <td>Trends in Job Seekers</td>\n",
       "      <td>・求職の新規登録者が増加せず、相変わらず人手不足が続いている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340740</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>Okinawa</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Unchanged</td>\n",
       "      <td>求人情報誌製作会社（営業）</td>\n",
       "      <td>Trends in Job Openings</td>\n",
       "      <td>・全体の求人数は、前月比で５％程度の微減である。３か月前と比較すると増減がなく横ばいである。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340741</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>Okinawa</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Unchanged</td>\n",
       "      <td>学校［大学］（就職支援担当）</td>\n",
       "      <td>Others</td>\n",
       "      <td>・物価高が続く限り、消費者は消費意欲を抑えるとみている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340742</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>Okinawa</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Slightly Bad</td>\n",
       "      <td>No response available</td>\n",
       "      <td>No response available</td>\n",
       "      <td>No response available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340743</th>\n",
       "      <td>2025</td>\n",
       "      <td>02</td>\n",
       "      <td>Okinawa</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Bad</td>\n",
       "      <td>No response available</td>\n",
       "      <td>No response available</td>\n",
       "      <td>No response available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340744 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year Month    Region               Topic Economic Judgment  \\\n",
       "0       2000    01  Hokkaido  Household Activity         Excellent   \n",
       "1       2000    01  Hokkaido  Household Activity              Good   \n",
       "2       2000    01  Hokkaido  Household Activity              Good   \n",
       "3       2000    01  Hokkaido  Household Activity         Unchanged   \n",
       "4       2000    01  Hokkaido  Household Activity         Unchanged   \n",
       "...      ...   ...       ...                 ...               ...   \n",
       "340739  2025    02   Okinawa          Employment         Unchanged   \n",
       "340740  2025    02   Okinawa          Employment         Unchanged   \n",
       "340741  2025    02   Okinawa          Employment         Unchanged   \n",
       "340742  2025    02   Okinawa          Employment      Slightly Bad   \n",
       "340743  2025    02   Okinawa          Employment               Bad   \n",
       "\n",
       "            Sector/Occupation     Reason for Judgment  \\\n",
       "0       No response available   No response available   \n",
       "1                     商店街代表者等                     NaN   \n",
       "2               レストラン（高級）スタッフ                     NaN   \n",
       "3                百貨店の売場主任・担当者                     NaN   \n",
       "4                  スーパーの店長・店員                     NaN   \n",
       "...                       ...                     ...   \n",
       "340739           人材派遣会社（総務担当）   Trends in Job Seekers   \n",
       "340740          求人情報誌製作会社（営業）  Trends in Job Openings   \n",
       "340741         学校［大学］（就職支援担当）                  Others   \n",
       "340742  No response available   No response available   \n",
       "340743  No response available   No response available   \n",
       "\n",
       "                                                  Details  \n",
       "0                                                     NaN  \n",
       "1                   ・価格が低下したことにより購買意欲が上向いており、売上点数が増加している。  \n",
       "2             ・２～３か月前と比べると、売上が伸びている。12月に比べると、２倍の伸びを示している。  \n",
       "3       ・３か月前と同様に、客は必要な物でも慎重な購買を行っている。今月スタートの冬物値下げで商品価...  \n",
       "4       ・今月は雪が多いせいもあり、良いとはいえない。客単価も悪く、店の状態をみる限り、景気は良いと...  \n",
       "...                                                   ...  \n",
       "340739                    ・求職の新規登録者が増加せず、相変わらず人手不足が続いている。  \n",
       "340740  ・全体の求人数は、前月比で５％程度の微減である。３か月前と比較すると増減がなく横ばいである。...  \n",
       "340741                       ・物価高が続く限り、消費者は消費意欲を抑えるとみている。  \n",
       "340742                              No response available  \n",
       "340743                              No response available  \n",
       "\n",
       "[340744 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace mapping\n",
    "region_dict = {'北海道': 'Hokkaido', '東北': 'Tohoku',\n",
    "               '北関東': 'Northern Kanto', '南関東': 'Southern Kanto',\n",
    "               '甲信越': 'Koshinetsu', '東海': 'Tokai', \n",
    "               '北陸': 'Hokuriku', '近畿': 'Kansai', \n",
    "               '中国': 'Chugoku', '四国': 'Shikoku', \n",
    "               '九州': 'Kyushu', '沖縄': 'Okinawa'}\n",
    "topic_dict = {'家計動向関連': 'Household Activity', '企業動向関連': 'Corporate Activity', '雇用関連': 'Employment'}\n",
    "judge_dict = {'◎': 'Excellent', '○': 'Good', '□': 'Unchanged', '▲': 'Slightly Bad', '×': 'Bad'}\n",
    "reason_dict = {\n",
    "    # sales prices\n",
    "    '単価の動き': 'Trends in Sales Price', \n",
    "    '受注単価や販売単価の動き': 'Trends in Sales Price', \n",
    "    '受注価格や販売': 'Trends in Sales Price',\n",
    "    '受注価格や販売価格': 'Trends in Sales Price', \n",
    "    '受注価格や販売価格の動き': 'Trends in Sales Price', \n",
    "    # sales volume\n",
    "    '販売量の動き': 'Trends in Sales Volume', \n",
    "    '受注量や販売量': 'Trends in Sales Volume', \n",
    "    '受注量や販売量の動き': 'Trends in Sales Volume',\n",
    "    # customers\n",
    "    '客の様子': 'Customer Behavior', \n",
    "    'お客様の様子': 'Customer Behavior', \n",
    "    'お客様の動き': 'Customer Behavior', \n",
    "    '来客数の動き': 'Trends in Customer Visits', \n",
    "    # client\n",
    "    '取引先の様子': 'Client Situation', \n",
    "    '取引先の動き': 'Client Situation',\n",
    "    # comptetior\n",
    "    '競争相手の様子': 'Competitor Situation', \n",
    "    '競争相手の動き': 'Competitor Situation', \n",
    "    # surrounding companies\n",
    "    '周辺企業の様子': 'Surrounding Companies Situation', \n",
    "    # employment\n",
    "    '求人数の動き': 'Trends in Job Openings', \n",
    "    '求人数の動き求人数の動き': 'Trends in Job Openings', \n",
    "    '求職者数の動き': 'Trends in Job Seekers',  \n",
    "    '採用者数の動き': 'Trends in Employment Numbers', \n",
    "    '雇用形態の様子': 'Trends in Employment Forms',\n",
    "    # miscellaneous\n",
    "    'それ以外': 'Others', \n",
    "    'その他': 'Others', \n",
    "    '＊': 'No significant responses available', \n",
    "    '－': 'No response available',\n",
    "    '・製造業、サービス業等を問わ': np.nan # error value\n",
    "}\n",
    "\n",
    "# replace\n",
    "combined_df['Region'] = combined_df['Region'].replace(region_dict)\n",
    "combined_df['Topic'] = combined_df['Topic'].replace(topic_dict)\n",
    "combined_df['Economic Judgment'] = combined_df['Economic Judgment'].replace(judge_dict)\n",
    "combined_df['Reason for Judgment'] = combined_df['Reason for Judgment'].replace(reason_dict)\n",
    "combined_df['Sector/Occupation'] = combined_df['Sector/Occupation'].replace({'＊': 'No significant responses available', '－': 'No response available'})\n",
    "combined_df['Details'] = combined_df['Details'].replace({'＊': 'No significant responses available', '－': 'No response available'})\n",
    "\n",
    "# show results\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc642cf5-9072-40f1-8be3-82ae7d9da843",
   "metadata": {},
   "source": [
    "- By generative AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3854063f-0d30-4970-880d-8deeee4e1496",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m     combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSector/Occupation\u001b[39m\u001b[38;5;124m'\u001b[39m], combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetails\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Run the asynchronous function (for Jupyter Notebook compatibility)\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Display the translated DataFrame\u001b[39;00m\n\u001b[0;32m     73\u001b[0m display(combined_df)\n",
      "Cell \u001b[1;32mIn[7], line 64\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Main function to translate specific columns in DataFrame\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     61\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mcreate_task(async_translate_column(combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSector/Occupation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)),\n\u001b[0;32m     62\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mcreate_task(async_translate_column(combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetails\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m))\n\u001b[0;32m     63\u001b[0m ]\n\u001b[1;32m---> 64\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Assign translated results back to DataFrame\u001b[39;00m\n\u001b[0;32m     67\u001b[0m combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSector/Occupation\u001b[39m\u001b[38;5;124m'\u001b[39m], combined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetails\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36masync_translate_column\u001b[1;34m(column_texts, batch_size)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(column_texts), batch_size):\n\u001b[0;32m     51\u001b[0m     batch \u001b[38;5;241m=\u001b[39m column_texts[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 52\u001b[0m     translated_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m async_translate_batch(batch, session\u001b[38;5;241m=\u001b[39msession)\n\u001b[0;32m     53\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(translated_batch)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# Reduce API load\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 31\u001b[0m, in \u001b[0;36masync_translate_batch\u001b[1;34m(texts, target_lang, session, attempt)\u001b[0m\n\u001b[0;32m     24\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauth_key\u001b[39m\u001b[38;5;124m'\u001b[39m: DEEPL_API_KEY,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: texts,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_lang\u001b[39m\u001b[38;5;124m'\u001b[39m: target_lang\n\u001b[0;32m     28\u001b[0m }\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mpost(API_URL, data\u001b[38;5;241m=\u001b[39mparams) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     32\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslations\u001b[39m\u001b[38;5;124m'\u001b[39m, [])]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\6502BDA\\Lib\\site-packages\\aiohttp\\client.py:1423\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[1;32m-> 1423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp: _RetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__aenter__\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\6502BDA\\Lib\\site-packages\\aiohttp\\client.py:728\u001b[0m, in \u001b[0;36mClientSession._request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[0;32m    726\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m req\u001b[38;5;241m.\u001b[39msend(conn)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 728\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstart(conn)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     resp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\6502BDA\\Lib\\site-packages\\aiohttp\\client_reqrep.py:1055\u001b[0m, in \u001b[0;36mClientResponse.start\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1054\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\n\u001b[1;32m-> 1055\u001b[0m     message, payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m http\u001b[38;5;241m.\u001b[39mHttpProcessingError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_info,\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1062\u001b[0m         headers\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1063\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\6502BDA\\Lib\\site-packages\\aiohttp\\streams.py:668\u001b[0m, in \u001b[0;36mDataQueue.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio\u001b[38;5;241m.\u001b[39mCancelledError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError):\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DeepL API key\n",
    "DEEPL_API_KEY = os.getenv('DEEPL_API_KEY_1')\n",
    "if not DEEPL_API_KEY:\n",
    "    raise ValueError(\"API key not found in .env file.\")\n",
    "API_URL = 'https://api.deepl.com/v2/translate'\n",
    "\n",
    "# Function to translate a batch of texts asynchronously\n",
    "async def async_translate_batch(texts, target_lang='EN-US', session=None, attempt=1):\n",
    "    \"\"\"Translate a batch of texts asynchronously using DeepL API\"\"\"\n",
    "    if not texts:\n",
    "        return []\n",
    "\n",
    "    # Prepare API request\n",
    "    params = {\n",
    "        'auth_key': DEEPL_API_KEY,\n",
    "        'text': texts,\n",
    "        'target_lang': target_lang\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        async with session.post(API_URL, data=params) as response:\n",
    "            result = await response.json()\n",
    "            return [t['text'] for t in result.get('translations', [])]\n",
    "\n",
    "    except Exception as e:\n",
    "        if attempt > 5:  # Retry up to 5 times\n",
    "            print(f'Translation failed for batch {texts}: {e}')\n",
    "            return ['Translation Error'] * len(texts)\n",
    "\n",
    "        wait_time = 2 ** attempt  # Exponential backoff\n",
    "        print(f'Retrying in {wait_time} seconds due to API error: {e}')\n",
    "        await asyncio.sleep(wait_time)\n",
    "        return await async_translate_batch(texts, target_lang, session, attempt + 1)\n",
    "\n",
    "# Function to translate an entire column asynchronously with batching\n",
    "async def async_translate_column(column_texts, batch_size=10):\n",
    "    \"\"\"Translate an entire column in batches asynchronously\"\"\"\n",
    "    results = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i in range(0, len(column_texts), batch_size):\n",
    "            batch = column_texts[i:i + batch_size]\n",
    "            translated_batch = await async_translate_batch(batch, session=session)\n",
    "            results.extend(translated_batch)\n",
    "            await asyncio.sleep(0.5)  # Reduce API load\n",
    "    return results\n",
    "\n",
    "# Main function to translate all necessary columns\n",
    "async def main():\n",
    "    \"\"\"Main function to translate specific columns in DataFrame\"\"\"\n",
    "    tasks = [\n",
    "        asyncio.create_task(async_translate_column(combined_df['Sector/Occupation'].tolist(), batch_size=50)),\n",
    "        asyncio.create_task(async_translate_column(combined_df['Details'].tolist(), batch_size=50))\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Assign translated results back to DataFrame\n",
    "    combined_df['Sector/Occupation'], combined_df['Details'] = results\n",
    "\n",
    "# Run the asynchronous function (for Jupyter Notebook compatibility)\n",
    "await main()\n",
    "\n",
    "# Display the translated DataFrame\n",
    "display(combined_df)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799d76d-1535-45cf-b8b3-d9f02fcbe543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the extra leading characters.\n",
    "combined_df['Details'] = combined_df['Details'].str.lstrip('・∙.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd526bbb-ed12-407b-844b-9819d84e5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save EWS data\n",
    "save_dir = '../data/2_EWS_en'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Define file paths using relative paths\n",
    "csv_file_path = os.path.join(save_dir, 'EWS_data_en.csv')\n",
    "pickle_file_path = os.path.join(save_dir, 'EWS_data_en.pkl')\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "combined_df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "# Save DataFrame to Pickle\n",
    "combined_df.to_pickle(pickle_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
